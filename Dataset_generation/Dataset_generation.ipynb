{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd4754-68d7-4994-830a-37f94bcef711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f463d-6f67-4edc-b4b1-4632d12b1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Much faster than transformers + bitsandbytes\n",
    "# llm = LLM(\n",
    "#     model=\"../Qwen2-VL-72B-Instruct\",\n",
    "#     tensor_parallel_size=1,          # Use multiple GPUs if available\n",
    "#     dtype=\"float16\",                 # Skip quantization for speed\n",
    "#     gpu_memory_utilization=0.9,      # Maximize GPU usage\n",
    "#     enforce_eager=False,             # Enable CUDA graphs\n",
    "#     # quantization=\"awq\",              # Use AWQ instead of bitsandbytes\n",
    "#     max_num_seqs=8                   # Batch processing\n",
    "# )\n",
    "\n",
    "# # Optimized sampling\n",
    "# sampling_params = SamplingParams(\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=512,\n",
    "#     top_p=0.9\n",
    "# )\n",
    "\n",
    "# # Generate (much faster)\n",
    "# outputs = llm.generate([\"Your prompt here\"], sampling_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e4269-7c57-40e0-ac91-6e0f8e69288f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb7859-c72d-42f3-9d18-20aa6b6ced2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c711b1-b4ca-4d4c-ae96-340565f611ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73977f05-fb6d-4e94-ae1b-678850840c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dff7ef-0be3-49cd-a693-8371d417891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simplified Seating Question Generator\n",
    "Generates seating arrangement questions and saves them as JSON\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "class SeatingQuestionGenerator:\n",
    "    def __init__(self, model, sampling_params, output_dir=\"generated_questions\"):\n",
    "        self.model = model\n",
    "        self.sampling_params = sampling_params\n",
    "        self.output_dir = output_dir\n",
    "        self.dataset = []\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "    def initialize_dataset(self, initial_samples: List[Dict]):\n",
    "        \"\"\"Initialize with seed questions.\"\"\"\n",
    "        self.dataset = initial_samples.copy()\n",
    "        self.save_dataset()\n",
    "        print(f\"Initialized dataset with {len(initial_samples)} questions\")\n",
    "    \n",
    "    def _create_generation_prompt(self, sample_questions: List[Dict], num_to_generate: int = 5) -> str:\n",
    "        \"\"\"Create prompt for generating new questions.\"\"\"\n",
    "        prompt = \"\"\"Generate seating arrangement logic questions following these examples. Each question should have:\n",
    "- A complex seating scenario (circular, linear, or parallel rows)\n",
    "- 4 multiple choice options (A, B, C, D)\n",
    "- Clear answer and explanation\n",
    "- Different people/professions/nationalities/beverages\n",
    "\n",
    "Examples:\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        for i, q in enumerate(sample_questions, 1):\n",
    "            prompt += f\"Example {i}:\\n\"\n",
    "            prompt += f\"Question: {q['question']}\\n\"\n",
    "            for choice in q['choices']:\n",
    "                prompt += f\"{choice}\\n\"\n",
    "            prompt += f\"Answer: {q['answer']}\\n\"\n",
    "            prompt += f\"Explanation: {q['explanation']}\\n\\n\"\n",
    "        \n",
    "        prompt += f\"Now generate {num_to_generate} new seating arrangement questions in the same format. Make them varied and challenging:\\n\\n\"\n",
    "        return prompt\n",
    "    \n",
    "    def _parse_generated_questions(self, outputs) -> List[Dict]:\n",
    "        \"\"\"Parse generated text into structured questions.\"\"\"\n",
    "        questions = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            text = output.outputs[0].text\n",
    "            \n",
    "            # Split by question markers\n",
    "            question_blocks = re.split(r'(?:Question \\d+:|New Question \\d+:|Generated Question \\d+:|\\n\\n(?=Question:))', text)\n",
    "            \n",
    "            for block in question_blocks:\n",
    "                if not block.strip():\n",
    "                    continue\n",
    "                \n",
    "                question_dict = self._extract_question_from_block(block)\n",
    "                if question_dict:\n",
    "                    questions.append(question_dict)\n",
    "        \n",
    "        return questions\n",
    "    \n",
    "    def _extract_question_from_block(self, block: str) -> Dict:\n",
    "        \"\"\"Extract structured question from text block.\"\"\"\n",
    "        try:\n",
    "            lines = [line.strip() for line in block.strip().split('\\n') if line.strip()]\n",
    "            \n",
    "            question_text = \"\"\n",
    "            choices = []\n",
    "            answer = \"\"\n",
    "            explanation = \"\"\n",
    "            \n",
    "            current_section = \"question\"\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Identify sections\n",
    "                if line.lower().startswith('question:'):\n",
    "                    current_section = \"question\"\n",
    "                    question_text = line[9:].strip()\n",
    "                elif re.match(r'^[A-D]\\)', line):\n",
    "                    current_section = \"choices\"\n",
    "                    choices.append(line)\n",
    "                elif line.lower().startswith('answer:'):\n",
    "                    current_section = \"answer\"\n",
    "                    answer = line[7:].strip().upper()\n",
    "                elif line.lower().startswith('explanation:'):\n",
    "                    current_section = \"explanation\"\n",
    "                    explanation = line[12:].strip()\n",
    "                else:\n",
    "                    # Continue current section\n",
    "                    if current_section == \"question\" and not question_text:\n",
    "                        question_text = line\n",
    "                    elif current_section == \"question\" and question_text:\n",
    "                        question_text += \" \" + line\n",
    "                    elif current_section == \"choices\" and re.match(r'^[A-D]\\)', line):\n",
    "                        choices.append(line)\n",
    "                    elif current_section == \"explanation\" and explanation:\n",
    "                        explanation += \" \" + line\n",
    "                    elif current_section == \"explanation\" and not explanation:\n",
    "                        explanation = line\n",
    "            \n",
    "            # Validate and return\n",
    "            if question_text and len(choices) == 4 and answer and explanation:\n",
    "                return {\n",
    "                    'question': question_text,\n",
    "                    'choices': choices,\n",
    "                    'answer': answer,\n",
    "                    'explanation': explanation,\n",
    "                    'generated_at': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing question block: {e}\")\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def generate_batch(self, num_questions: int = 5) -> List[Dict]:\n",
    "        \"\"\"Generate a batch of new questions.\"\"\"\n",
    "        new_questions = []\n",
    "        \n",
    "        # Select random sample questions for context\n",
    "        sample_questions = random.sample(self.dataset, min(3, len(self.dataset)))\n",
    "        prompt = self._create_generation_prompt(sample_questions, num_questions)\n",
    "        \n",
    "        try:\n",
    "            outputs = self.model.generate([prompt], self.sampling_params)\n",
    "            questions = self._parse_generated_questions(outputs)\n",
    "            \n",
    "            for q in questions:\n",
    "                if q:  # Simple validation\n",
    "                    new_questions.append(q)\n",
    "                    if len(new_questions) >= num_questions:\n",
    "                        break\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Generation failed: {e}\")\n",
    "            \n",
    "        self.dataset.extend(new_questions)\n",
    "        if new_questions:\n",
    "            self.save_dataset()\n",
    "        \n",
    "        return new_questions\n",
    "    \n",
    "    def save_dataset(self):\n",
    "        \"\"\"Save the current dataset to JSON.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{self.output_dir}/seating_questions.json\"\n",
    "        \n",
    "        dataset_info = {\n",
    "            'metadata': {\n",
    "                'total_questions': len(self.dataset),\n",
    "                'generated_at': datetime.now().isoformat(),\n",
    "                'model_name': 'Qwen2-VL-72B-Instruct'\n",
    "            },\n",
    "            'questions': self.dataset\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        # Also save latest version\n",
    "        latest_filename = f\"{self.output_dir}/1000_latest_dataset.json\"\n",
    "        with open(latest_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        print(f\"Dataset saved to {filename}\")\n",
    "        \n",
    "    def generate_dataset(self, target_size: int, batch_size: int = 5):\n",
    "        \"\"\"Generate dataset to reach target size.\"\"\"\n",
    "        print(f\"Generating dataset to reach {target_size} questions...\")\n",
    "        \n",
    "        while len(self.dataset) < target_size:\n",
    "            remaining = target_size - len(self.dataset)\n",
    "            current_batch_size = min(batch_size, remaining)\n",
    "            \n",
    "            print(f\"Progress: {len(self.dataset)}/{target_size}\")\n",
    "            new_questions = self.generate_batch(current_batch_size)\n",
    "            \n",
    "            if not new_questions:\n",
    "                print(\"Warning: No new questions generated. Stopping.\")\n",
    "                # break\n",
    "                \n",
    "        print(f\"Dataset generation complete! Final size: {len(self.dataset)}\")\n",
    "        return self.dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92e7ac-c0b8-4459-bece-f0073674fbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Load the model with optimized settings.\"\"\"\n",
    "    print(\"Loading model...\")\n",
    "    \n",
    "    try:\n",
    "        llm = LLM(\n",
    "            model=\"Qwen/Qwen2-VL-72B-Instruct\",  # or your local path\n",
    "            tensor_parallel_size=1,\n",
    "            dtype=\"float16\",\n",
    "            gpu_memory_utilization=0.9,\n",
    "            max_num_seqs=4\n",
    "        )\n",
    "        \n",
    "        sampling_params = SamplingParams(\n",
    "            temperature=0.8,\n",
    "            max_tokens=1024,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        return llm, sampling_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def get_initial_samples():\n",
    "    \"\"\"Get seed questions for the generator.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"question\": \"Five friends from different countries sit circularly. The Italian sits opposite the tea-drinker. The Japanese sits two seats to the left of the coffee-drinker. The Brazilian drinks juice. The Chinese is adjacent to the American. Milk is drunk by someone adjacent to juice. Who drinks coffee?\",\n",
    "            \"choices\": [\n",
    "                \"A) American\",\n",
    "                \"B) Chinese\", \n",
    "                \"C) Japanese\",\n",
    "                \"D) Brazilian\"\n",
    "            ],\n",
    "            \"answer\": \"A\",\n",
    "            \"explanation\": \"Brazilian (juice) has milk adjacent. Italian opposite tea. Japanese -> 2 seats left of coffee -> American must be coffee (Chinese adjacent to American, not conflicting with other constraints).\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Eight people A, B, C, D, E, F, G, H sit around a circular table. Four face the center, and four face outward. A is third to the left of B, who faces the opposite direction of D. C (a doctor) sits adjacent to both E and F. G faces the center and is two seats to the left of H, who is not adjacent to B. If E faces outward, who is the engineer?\",\n",
    "            \"choices\": [\n",
    "                \"A) G\",\n",
    "                \"B) H\",\n",
    "                \"C) F\", \n",
    "                \"D) D\"\n",
    "            ],\n",
    "            \"answer\": \"B\",\n",
    "            \"explanation\": \"H's position and facing direction (outward) are derived from clues. Since C is a doctor and professions aren't repeated, H must be the engineer.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Six people sit in a straight line facing north. The engineer sits at one end. The doctor is two seats away from the lawyer. The teacher sits immediately to the right of the scientist. The manager is not adjacent to the engineer. If the artist sits between the doctor and teacher, who sits at the left end?\",\n",
    "            \"choices\": [\n",
    "                \"A) Engineer\",\n",
    "                \"B) Doctor\",\n",
    "                \"C) Manager\", \n",
    "                \"D) Scientist\"\n",
    "            ],\n",
    "            \"answer\": \"A\",\n",
    "            \"explanation\": \"Working through the constraints systematically: engineer must be at an end, and given the positioning requirements of other professions, the engineer sits at the left end.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"SEATING ARRANGEMENT QUESTION GENERATOR\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load model\n",
    "    model, sampling_params = load_model()\n",
    "    if not model:\n",
    "        print(\"Failed to load model. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = SeatingQuestionGenerator(model, sampling_params)\n",
    "    \n",
    "    # Load initial samples\n",
    "    initial_samples = get_initial_samples()\n",
    "    generator.initialize_dataset(initial_samples)\n",
    "    \n",
    "    # Generate more questions\n",
    "    target_questions = 1000  # Adjust as needed\n",
    "    generator.generate_dataset(target_questions, batch_size=3)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"GENERATION COMPLETE!\")\n",
    "    print(f\"Total questions: {len(generator.dataset)}\")\n",
    "    print(f\"Saved to: {generator.output_dir}/latest_dataset.json\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933aeddc-91e9-4516-939f-048b94018746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8a5eb-2ab5-4a96-9ca5-6a5a95892feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4a26d-9c60-4845-ae74-99b370e306fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3adcc4-c242-48fe-a001-27f2f0edba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b9f5a-74c9-4b1e-825e-11fa20808430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f84fa6-a3d3-4834-94cd-e32ee6fe7f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954450d7-bf9e-4a87-8b3e-dfc2010e3c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee46d6-5712-41ce-920c-098190607754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import random\n",
    "# from typing import List, Dict\n",
    "\n",
    "# def create_generation_prompt(sample_questions: List[Dict], num_to_generate: int = 5) -> str:\n",
    "#     \"\"\"\n",
    "#     Create a prompt for generating seating arrangement questions based on samples.\n",
    "#     Returns a prompt that generates questions in proper JSON schema format.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Format the sample questions\n",
    "#     examples_text = \"\"\n",
    "#     for i, q in enumerate(sample_questions, 1):\n",
    "#         examples_text += f\"\"\"\n",
    "# Example {i}:\n",
    "# Question: {q['question']}\n",
    "# Choices: {q.get('choices', ['A) Option 1', 'B) Option 2', 'C) Option 3', 'D) Option 4'])}\n",
    "# Answer: {q['answer']}\n",
    "# Explanation: {q['explanation']}\n",
    "# \"\"\"\n",
    "    \n",
    "#     prompt = f\"\"\"You are an expert at creating seating arrangement reasoning questions for competitive exams. \n",
    "# Here are {len(sample_questions)} example questions with their answers and explanations:\n",
    "# {examples_text}\n",
    "\n",
    "# Now generate {num_to_generate} NEW seating arrangement questions following these guidelines:\n",
    "\n",
    "# QUESTION TYPES TO VARY:\n",
    "# - Circular seating (5-12 people)\n",
    "# - Linear seating (single row, 6-10 people)  \n",
    "# - Parallel rows (2 rows, 4-8 people each)\n",
    "\n",
    "# ELEMENTS TO INCLUDE (mix and match):\n",
    "# - Nationalities (American, Brazilian, Chinese, Indian, Japanese, German, French, Italian)\n",
    "# - Professions (Doctor, Engineer, Teacher, Lawyer, Manager, Scientist, Artist)\n",
    "# - Beverages (Tea, Coffee, Juice, Milk, Water, Soda)\n",
    "# - Facing directions (center/outward for circular, north/south for linear)\n",
    "# - Colors (Red, Blue, Green, Yellow, Black, White)\n",
    "# - Ages (use relative terms like \"younger than\", \"older than\")\n",
    "\n",
    "# CONSTRAINTS TO USE:\n",
    "# - Opposite positions\n",
    "# - Adjacent positions  \n",
    "# - Specific seat numbers/positions\n",
    "# - \"X seats to the left/right of Y\"\n",
    "# - \"Between X and Y\"\n",
    "# - Directional facing requirements\n",
    "\n",
    "# MANDATORY REQUIREMENTS:\n",
    "# 1. Each question MUST have exactly 4 multiple choice options labeled A), B), C), D)\n",
    "# 2. Questions must be solvable through logical deduction\n",
    "# 3. Each question should be unique and test different reasoning patterns\n",
    "# 4. Answer choices should be plausible and relevant to the question asked\n",
    "\n",
    "# OUTPUT FORMAT - MUST be a valid JSON object with this exact structure:\n",
    "# {{\n",
    "#   \"questions\": [\n",
    "#     {{\n",
    "#       \"question\": \"[Complete question text ending with a clear question]\",\n",
    "#       \"choices\": [\n",
    "#         \"A) [Option 1]\",\n",
    "#         \"B) [Option 2]\", \n",
    "#         \"C) [Option 3]\",\n",
    "#         \"D) [Option 4]\"\n",
    "#       ],\n",
    "#       \"answer\": \"[Single letter A, B, C, or D]\",\n",
    "#       \"explanation\": \"[Step-by-step logical reasoning showing how to arrive at the answer]\"\n",
    "#     }}\n",
    "#   ]\n",
    "# }}\n",
    "\n",
    "# CRITICAL: \n",
    "# - Output ONLY valid JSON - no commentary, no extra text\n",
    "# - Ensure all JSON syntax is correct (proper quotes, commas, brackets)\n",
    "# - Each question object must include all four fields: question, choices, answer, explanation\n",
    "# - Choices must always be an array of exactly 4 strings starting with A), B), C), D)\n",
    "\n",
    "# Generate exactly {num_to_generate} questions now:\"\"\"\n",
    "    \n",
    "#     return prompt\n",
    "\n",
    "# # Initialize your sample dataset with proper structure\n",
    "# initial_samples = [\n",
    "    # {\n",
    "    #     \"question\": \"Five friends from different countries sit circularly. The Italian sits opposite the tea-drinker. The Japanese sits two seats to the left of the coffee-drinker. The Brazilian drinks juice. The Chinese is adjacent to the American. Milk is drunk by someone adjacent to juice. Who drinks coffee?\",\n",
    "    #     \"choices\": [\n",
    "    #         \"A) American\",\n",
    "    #         \"B) Chinese\", \n",
    "    #         \"C) Japanese\",\n",
    "    #         \"D) Brazilian\"\n",
    "    #     ],\n",
    "    #     \"answer\": \"A\",\n",
    "    #     \"explanation\": \"Brazilian (juice) has milk adjacent. Italian opposite tea. Japanese -> 2 seats left of coffee -> American must be coffee (Chinese adjacent to American, not conflicting with other constraints).\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"question\": \"Eight people A, B, C, D, E, F, G, H sit around a circular table. Four face the center, and four face outward. A is third to the left of B, who faces the opposite direction of D. C (a doctor) sits adjacent to both E and F. G faces the center and is two seats to the left of H, who is not adjacent to B. If E faces outward, who is the engineer?\",\n",
    "    #     \"choices\": [\n",
    "    #         \"A) G\",\n",
    "    #         \"B) H\",\n",
    "    #         \"C) F\", \n",
    "    #         \"D) D\"\n",
    "    #     ],\n",
    "    #     \"answer\": \"B\",\n",
    "    #     \"explanation\": \"H's position and facing direction (outward) are derived from clues. Since C is a doctor and professions aren't repeated, H must be the engineer.\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"question\": \"Twelve people sit in two parallel rows of six each. Front row faces south, back row faces north. P is behind Q, who is third from the left end. R faces T, who is adjacent to S. U is two places to the right of V in the same row. If W is at an extreme end in the back row, who sits at the front row's extreme right?\",\n",
    "    #     \"choices\": [\n",
    "    #         \"A) S\",\n",
    "    #         \"B) T\",\n",
    "    #         \"C) U\",\n",
    "    #         \"D) V\"\n",
    "    #     ],\n",
    "    #     \"answer\": \"A\", \n",
    "    #     \"explanation\": \"Q is third from left in front row; P is behind Q. R faces T (adjacent to S). U and V positions fix S at the front right.\"\n",
    "    # }\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941eaa15-b4c4-42bc-8841-628f6757923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c58243-7907-46bc-9456-043c3e781ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data_emnlp_final/data_06b8f2a1/1.3_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1736cde3-7b03-495f-aed3-edbf895b7520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>story</th>\n",
       "      <th>query</th>\n",
       "      <th>text_query</th>\n",
       "      <th>target</th>\n",
       "      <th>text_target</th>\n",
       "      <th>clean_story</th>\n",
       "      <th>proof_state</th>\n",
       "      <th>f_comb</th>\n",
       "      <th>task_name</th>\n",
       "      <th>story_edges</th>\n",
       "      <th>edge_types</th>\n",
       "      <th>query_edge</th>\n",
       "      <th>genders</th>\n",
       "      <th>syn_story</th>\n",
       "      <th>node_mapping</th>\n",
       "      <th>task_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5e249ede-4823-428d-b7fa-2d3deb8ed858</td>\n",
       "      <td>[Wayne] was out with his son [Matthew]. Later ...</td>\n",
       "      <td>('Johanna', 'Henry')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>father</td>\n",
       "      <td>[\"[Johanna] 'father [Henry] became enraged whe...</td>\n",
       "      <td>[Johanna] enjoyed a homemade dinner with her s...</td>\n",
       "      <td>[{('Johanna', 'father', 'Henry'): [('Johanna',...</td>\n",
       "      <td>son-father-father</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['son', 'father', 'father']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Johanna:female,Matthew:male,Wayne:male,Henry:male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{4: 0, 19: 1, 16: 2, 0: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14b8bd60-5d9f-4332-8f6c-1e0697541f7f</td>\n",
       "      <td>[Young] and his sister [Kathleen] have been be...</td>\n",
       "      <td>('Young', 'Donna')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mother</td>\n",
       "      <td>[\"[Young]'s mother, [Donna], waited impatientl...</td>\n",
       "      <td>[Young] and his sister [Kathleen] have been be...</td>\n",
       "      <td>[{('Young', 'mother', 'Donna'): [('Young', 'si...</td>\n",
       "      <td>sister-daughter-grandmother</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['sister', 'daughter', 'grandmother']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Young:male,Kathleen:female,Kari:female,Donna:f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{2: 0, 3: 1, 15: 2, 1: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fe81eae5-c860-417f-8272-fbea0585d016</td>\n",
       "      <td>[Kathleen] was excited because she was meeting...</td>\n",
       "      <td>('Wayne', 'Henry')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>father</td>\n",
       "      <td>['[Henry] was so proud of his son, [Wayne]. he...</td>\n",
       "      <td>[Howard] and his son [Wayne] went to look at c...</td>\n",
       "      <td>[{('Wayne', 'father', 'Henry'): [('Wayne', 'si...</td>\n",
       "      <td>son-aunt-father</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['son', 'aunt', 'father']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Wayne:male,Howard:male,Kathleen:female,Henry:male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{16: 0, 17: 1, 3: 2, 0: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1d88afe8-4feb-4adc-8940-b588b9771f24</td>\n",
       "      <td>[Marian] asked her mother, [Donna], what they ...</td>\n",
       "      <td>('Kari', 'Donna')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>['[Kari] takes good care of her grandmother, [...</td>\n",
       "      <td>[Kari] asked her mother, [Kathleen], what they...</td>\n",
       "      <td>[{('Kari', 'grandmother', 'Donna'): [('Kari', ...</td>\n",
       "      <td>mother-sister-mother</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['mother', 'sister', 'mother']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Kari:female,Kathleen:female,Marian:female,Donn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{15: 0, 3: 1, 5: 2, 1: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4f02072c-8636-45d8-8b3f-5ad062ece354</td>\n",
       "      <td>[Ricky] invited his mother [Ashley] and grandm...</td>\n",
       "      <td>('Young', 'Donna')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mother</td>\n",
       "      <td>['[Donna] gave birth to a son named [Young].']</td>\n",
       "      <td>[Ashley] picked up her husband, [Young] from t...</td>\n",
       "      <td>[{('Young', 'mother', 'Donna'): [('Young', 'so...</td>\n",
       "      <td>wife-son-grandmother</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['wife', 'son', 'grandmother']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Young:male,Ashley:female,Ricky:male,Donna:female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{2: 0, 6: 1, 8: 2, 1: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>bf3525a3-11bb-4654-b575-f6f36a52061d</td>\n",
       "      <td>[Philip]'s mother, [Donna], took him shopping ...</td>\n",
       "      <td>('Marian', 'Donna')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mother</td>\n",
       "      <td>['[Donna] had a daughter named [Marian].']</td>\n",
       "      <td>[Marian] went to her son [Joseph]'s House [Phi...</td>\n",
       "      <td>[{('Marian', 'mother', 'Donna'): [('Marian', '...</td>\n",
       "      <td>son-father-mother</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['son', 'father', 'mother']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Marian:female,Joseph:male,Philip:male,Donna:fe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{5: 0, 22: 1, 21: 2, 1: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>2c62bd8a-a1c9-4775-aafb-530cbb1f589a</td>\n",
       "      <td>[Marian] loves her son [Devin] very much. He l...</td>\n",
       "      <td>('Marian', 'Henry')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>father</td>\n",
       "      <td>['[Marian] took her father, [Henry], out to di...</td>\n",
       "      <td>[Marian] loves her son [Devin] very much. He l...</td>\n",
       "      <td>[{('Marian', 'father', 'Henry'): [('Marian', '...</td>\n",
       "      <td>son-father-father</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['son', 'father', 'father']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Marian:female,Devin:male,Philip:male,Henry:male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{5: 0, 23: 1, 21: 2, 0: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>d4c7c9cc-a240-49fd-8d8a-efc698fda628</td>\n",
       "      <td>[Howard] went to lunch with his aunt [Marian]....</td>\n",
       "      <td>('Wayne', 'Henry')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>father</td>\n",
       "      <td>['[Henry] was so proud of his son, [Wayne]. he...</td>\n",
       "      <td>[Howard] took his favorite son [Wayne] to a ba...</td>\n",
       "      <td>[{('Wayne', 'father', 'Henry'): [('Wayne', 'si...</td>\n",
       "      <td>son-aunt-father</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['son', 'aunt', 'father']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Wayne:male,Howard:male,Marian:female,Henry:male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{16: 0, 17: 1, 5: 2, 0: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>54acd335-1add-4062-bf86-6e90ea643749</td>\n",
       "      <td>[Kathleen] just had a baby and presented the b...</td>\n",
       "      <td>('Sarah', 'Donna')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>['[Sarah] asked her mother [Donna] if she coul...</td>\n",
       "      <td>[Sarah] asked her mother, [Johanna], what they...</td>\n",
       "      <td>[{('Sarah', 'grandmother', 'Donna'): [('Sarah'...</td>\n",
       "      <td>mother-sister-mother</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['mother', 'sister', 'mother']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Sarah:female,Johanna:female,Kathleen:female,Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{20: 0, 4: 1, 3: 2, 1: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>f636b396-79bd-47a5-9b64-58810209ae11</td>\n",
       "      <td>[Kathleen] spent a great day shopping with her...</td>\n",
       "      <td>('Young', 'Donna')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mother</td>\n",
       "      <td>['[Donna] is proud that her son graduated coll...</td>\n",
       "      <td>[Kathleen] and [Young] are siblings who are en...</td>\n",
       "      <td>[{('Young', 'mother', 'Donna'): [('Young', 'si...</td>\n",
       "      <td>sister-daughter-grandmother</td>\n",
       "      <td>task_1.3</td>\n",
       "      <td>[(0, 1), (1, 2), (2, 3)]</td>\n",
       "      <td>['sister', 'daughter', 'grandmother']</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>Young:male,Kathleen:female,Nicole:female,Donna...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{2: 0, 3: 1, 12: 2, 1: 3}</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                    id  \\\n",
       "0             0  5e249ede-4823-428d-b7fa-2d3deb8ed858   \n",
       "1             1  14b8bd60-5d9f-4332-8f6c-1e0697541f7f   \n",
       "2             2  fe81eae5-c860-417f-8272-fbea0585d016   \n",
       "3             3  1d88afe8-4feb-4adc-8940-b588b9771f24   \n",
       "4             4  4f02072c-8636-45d8-8b3f-5ad062ece354   \n",
       "..          ...                                   ...   \n",
       "96           96  bf3525a3-11bb-4654-b575-f6f36a52061d   \n",
       "97           97  2c62bd8a-a1c9-4775-aafb-530cbb1f589a   \n",
       "98           98  d4c7c9cc-a240-49fd-8d8a-efc698fda628   \n",
       "99           99  54acd335-1add-4062-bf86-6e90ea643749   \n",
       "100         100  f636b396-79bd-47a5-9b64-58810209ae11   \n",
       "\n",
       "                                                 story                 query  \\\n",
       "0    [Wayne] was out with his son [Matthew]. Later ...  ('Johanna', 'Henry')   \n",
       "1    [Young] and his sister [Kathleen] have been be...    ('Young', 'Donna')   \n",
       "2    [Kathleen] was excited because she was meeting...    ('Wayne', 'Henry')   \n",
       "3    [Marian] asked her mother, [Donna], what they ...     ('Kari', 'Donna')   \n",
       "4    [Ricky] invited his mother [Ashley] and grandm...    ('Young', 'Donna')   \n",
       "..                                                 ...                   ...   \n",
       "96   [Philip]'s mother, [Donna], took him shopping ...   ('Marian', 'Donna')   \n",
       "97   [Marian] loves her son [Devin] very much. He l...   ('Marian', 'Henry')   \n",
       "98   [Howard] went to lunch with his aunt [Marian]....    ('Wayne', 'Henry')   \n",
       "99   [Kathleen] just had a baby and presented the b...    ('Sarah', 'Donna')   \n",
       "100  [Kathleen] spent a great day shopping with her...    ('Young', 'Donna')   \n",
       "\n",
       "     text_query       target  \\\n",
       "0           NaN       father   \n",
       "1           NaN       mother   \n",
       "2           NaN       father   \n",
       "3           NaN  grandmother   \n",
       "4           NaN       mother   \n",
       "..          ...          ...   \n",
       "96          NaN       mother   \n",
       "97          NaN       father   \n",
       "98          NaN       father   \n",
       "99          NaN  grandmother   \n",
       "100         NaN       mother   \n",
       "\n",
       "                                           text_target  \\\n",
       "0    [\"[Johanna] 'father [Henry] became enraged whe...   \n",
       "1    [\"[Young]'s mother, [Donna], waited impatientl...   \n",
       "2    ['[Henry] was so proud of his son, [Wayne]. he...   \n",
       "3    ['[Kari] takes good care of her grandmother, [...   \n",
       "4       ['[Donna] gave birth to a son named [Young].']   \n",
       "..                                                 ...   \n",
       "96          ['[Donna] had a daughter named [Marian].']   \n",
       "97   ['[Marian] took her father, [Henry], out to di...   \n",
       "98   ['[Henry] was so proud of his son, [Wayne]. he...   \n",
       "99   ['[Sarah] asked her mother [Donna] if she coul...   \n",
       "100  ['[Donna] is proud that her son graduated coll...   \n",
       "\n",
       "                                           clean_story  \\\n",
       "0    [Johanna] enjoyed a homemade dinner with her s...   \n",
       "1    [Young] and his sister [Kathleen] have been be...   \n",
       "2    [Howard] and his son [Wayne] went to look at c...   \n",
       "3    [Kari] asked her mother, [Kathleen], what they...   \n",
       "4    [Ashley] picked up her husband, [Young] from t...   \n",
       "..                                                 ...   \n",
       "96   [Marian] went to her son [Joseph]'s House [Phi...   \n",
       "97   [Marian] loves her son [Devin] very much. He l...   \n",
       "98   [Howard] took his favorite son [Wayne] to a ba...   \n",
       "99   [Sarah] asked her mother, [Johanna], what they...   \n",
       "100  [Kathleen] and [Young] are siblings who are en...   \n",
       "\n",
       "                                           proof_state  \\\n",
       "0    [{('Johanna', 'father', 'Henry'): [('Johanna',...   \n",
       "1    [{('Young', 'mother', 'Donna'): [('Young', 'si...   \n",
       "2    [{('Wayne', 'father', 'Henry'): [('Wayne', 'si...   \n",
       "3    [{('Kari', 'grandmother', 'Donna'): [('Kari', ...   \n",
       "4    [{('Young', 'mother', 'Donna'): [('Young', 'so...   \n",
       "..                                                 ...   \n",
       "96   [{('Marian', 'mother', 'Donna'): [('Marian', '...   \n",
       "97   [{('Marian', 'father', 'Henry'): [('Marian', '...   \n",
       "98   [{('Wayne', 'father', 'Henry'): [('Wayne', 'si...   \n",
       "99   [{('Sarah', 'grandmother', 'Donna'): [('Sarah'...   \n",
       "100  [{('Young', 'mother', 'Donna'): [('Young', 'si...   \n",
       "\n",
       "                          f_comb task_name               story_edges  \\\n",
       "0              son-father-father  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "1    sister-daughter-grandmother  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "2                son-aunt-father  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "3           mother-sister-mother  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "4           wife-son-grandmother  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "..                           ...       ...                       ...   \n",
       "96             son-father-mother  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "97             son-father-father  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "98               son-aunt-father  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "99          mother-sister-mother  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "100  sister-daughter-grandmother  task_1.3  [(0, 1), (1, 2), (2, 3)]   \n",
       "\n",
       "                                edge_types query_edge  \\\n",
       "0              ['son', 'father', 'father']     (0, 3)   \n",
       "1    ['sister', 'daughter', 'grandmother']     (0, 3)   \n",
       "2                ['son', 'aunt', 'father']     (0, 3)   \n",
       "3           ['mother', 'sister', 'mother']     (0, 3)   \n",
       "4           ['wife', 'son', 'grandmother']     (0, 3)   \n",
       "..                                     ...        ...   \n",
       "96             ['son', 'father', 'mother']     (0, 3)   \n",
       "97             ['son', 'father', 'father']     (0, 3)   \n",
       "98               ['son', 'aunt', 'father']     (0, 3)   \n",
       "99          ['mother', 'sister', 'mother']     (0, 3)   \n",
       "100  ['sister', 'daughter', 'grandmother']     (0, 3)   \n",
       "\n",
       "                                               genders  syn_story  \\\n",
       "0    Johanna:female,Matthew:male,Wayne:male,Henry:male        NaN   \n",
       "1    Young:male,Kathleen:female,Kari:female,Donna:f...        NaN   \n",
       "2    Wayne:male,Howard:male,Kathleen:female,Henry:male        NaN   \n",
       "3    Kari:female,Kathleen:female,Marian:female,Donn...        NaN   \n",
       "4     Young:male,Ashley:female,Ricky:male,Donna:female        NaN   \n",
       "..                                                 ...        ...   \n",
       "96   Marian:female,Joseph:male,Philip:male,Donna:fe...        NaN   \n",
       "97     Marian:female,Devin:male,Philip:male,Henry:male        NaN   \n",
       "98     Wayne:male,Howard:male,Marian:female,Henry:male        NaN   \n",
       "99   Sarah:female,Johanna:female,Kathleen:female,Do...        NaN   \n",
       "100  Young:male,Kathleen:female,Nicole:female,Donna...        NaN   \n",
       "\n",
       "                   node_mapping task_split  \n",
       "0    {4: 0, 19: 1, 16: 2, 0: 3}       test  \n",
       "1     {2: 0, 3: 1, 15: 2, 1: 3}       test  \n",
       "2    {16: 0, 17: 1, 3: 2, 0: 3}       test  \n",
       "3     {15: 0, 3: 1, 5: 2, 1: 3}       test  \n",
       "4      {2: 0, 6: 1, 8: 2, 1: 3}       test  \n",
       "..                          ...        ...  \n",
       "96   {5: 0, 22: 1, 21: 2, 1: 3}       test  \n",
       "97   {5: 0, 23: 1, 21: 2, 0: 3}       test  \n",
       "98   {16: 0, 17: 1, 5: 2, 0: 3}       test  \n",
       "99    {20: 0, 4: 1, 3: 2, 1: 3}       test  \n",
       "100   {2: 0, 3: 1, 12: 2, 1: 3}       test  \n",
       "\n",
       "[101 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58928e9d-8457-4069-93a9-70f21a63c0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Wayne] was out with his son [Matthew]. Later that day they went to see [Wayne]'s father, [Henry]. [Johanna] enjoyed a homemade dinner with her son [Matthew]\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb82b811-0287-4117-9d96-64e176ad3739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'story', 'query', 'text_query', 'target',\n",
       "       'text_target', 'clean_story', 'proof_state', 'f_comb', 'task_name',\n",
       "       'story_edges', 'edge_types', 'query_edge', 'genders', 'syn_story',\n",
       "       'node_mapping', 'task_split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58683868-a1c1-4df2-910e-db414ab0a80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"[Johanna] \\'father [Henry] became enraged when she failed to complete her homework. [Johanna] was grounded for a month and unable to spend time with friends.\"]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['text_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccca7790-d861-4367-bad9-5f339bd858d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johanna:female,Matthew:male,Wayne:male,Henry:male'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['genders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb25989-33e9-4300-8c88-5bf3d7d2b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{('Johanna', 'father', 'Henry'): [('Johanna', 'son', 'Matthew'), ('Matthew', 'grandfather', 'Henry')]}, {('Matthew', 'grandfather', 'Henry'): [('Matthew', 'father', 'Wayne'), ('Wayne', 'father', 'Henry')]}]\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['proof_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6591cf70-cbb6-4183-9234-b39d50d8883c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('Young', 'mother', 'Donna'): [('Young', 'son', 'Stephen'),\n",
       "   ('Stephen', 'grandmother', 'Donna')]},\n",
       " {('Young', 'son', 'Stephen'): [('Young', 'wife', 'Ashley'),\n",
       "   ('Ashley', 'son', 'Stephen')]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "raw = df.iloc[10]['proof_state']\n",
    "parsed = ast.literal_eval(raw)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09af0585-3fa8-4440-8fd1-478485f9edfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('Young', 'son', 'Stephen')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a4f26d9-255b-4309-824e-4debb6c364f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alicia', 'Ann', 'Ashley', 'Cedric', 'Dale', 'Devin', 'Donald', 'Donna', 'Edward', 'Gloria', 'Heath', 'Henry', 'Howard', 'Jack', 'James', 'Janet', 'Johanna', 'John', 'Joseph', 'Kari', 'Kathleen', 'Lance', 'Laura', 'Lillian', 'Lourdes', 'Marian', 'Matthew', 'Myrna', 'Nicole', 'Noreen', 'Philip', 'Ricky', 'Rita', 'Sarah', 'Stephen', 'Tammy', 'Vickie', 'Wayne', 'William', 'Young']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "all_names = set()\n",
    "\n",
    "for row in df['proof_state']:\n",
    "    try:\n",
    "        parsed = ast.literal_eval(row)\n",
    "        for rule in parsed:\n",
    "            for head, body in rule.items():\n",
    "                all_names.add(head[0])\n",
    "                all_names.add(head[2])\n",
    "                for triplet in body:\n",
    "                    all_names.add(triplet[0])\n",
    "                    all_names.add(triplet[2])\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing row: {e}\")\n",
    "\n",
    "print(sorted(all_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f678a04-ff6e-4da3-ac30-add19c61397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 676 distinct names: ['Aaron', 'Adam', 'Adan', 'Adelia', 'Adeline', 'Adrian', 'Aida', 'Alan', 'Albert', 'Alberta', 'Alex', 'Alfred', 'Alfredo', 'Alice', 'Alicia', 'Alisa', 'Alison', 'Allan', 'Allen', 'Alma', 'Alverta', 'Alvin', 'Amalia', 'Amanda', 'Amber', 'Amelia', 'Amy', 'Andrea', 'Andres', 'Andrew', 'Andy', 'Angel', 'Angela', 'Angelica', 'Angelina', 'Anita', 'Ann', 'Anna', 'Anne', 'Annette', 'Annie', 'Anthony', 'Antonia', 'Antonio', 'April', 'Arlene', 'Armando', 'Arnold', 'Arthur', 'Ashley', 'Asia', 'Audry', 'Aurora', 'Autumn', 'Avis', 'Barbara', 'Barry', 'Beatrice', 'Belinda', 'Belva', 'Ben', 'Benito', 'Benjamin', 'Benny', 'Bernard', 'Bernardo', 'Bertha', 'Beth', 'Bettie', 'Betty', 'Beverly', 'Billie', 'Billy', 'Blanca', 'Bobby', 'Bonita', 'Bonnie', 'Brad', 'Brandi', 'Brandon', 'Brenda', 'Brent', 'Bret', 'Brian', 'Bridget', 'Bridgett', 'Brittney', 'Bruce', 'Bryan', 'Candace', 'Carl', 'Carla', 'Carlos', 'Carly', 'Carmelita', 'Carmen', 'Carol', 'Carolina', 'Carolyn', 'Carrie', 'Casey', 'Catherine', 'Cathrine', 'Cathy', 'Cecelia', 'Cecil', 'Cecilia', 'Cedric', 'Cesar', 'Chad', 'Charlene', 'Charles', 'Charlie', 'Charlotte', 'Charlsie', 'Cheryl', 'Chris', 'Christian', 'Christina', 'Christine', 'Christopher', 'Chuck', 'Cindy', 'Claire', 'Clara', 'Clarence', 'Claudia', 'Cleo', 'Clifton', 'Clyde', 'Colin', 'Colleen', 'Connie', 'Constance', 'Cornelius', 'Cory', 'Courtney', 'Craig', 'Cristina', 'Cruz', 'Crystal', 'Cyrus', 'Dale', 'Dallas', 'Dan', 'Dana', 'Daniel', 'Danielle', 'Danita', 'Dannielle', 'Danny', 'Darlene', 'Darnell', 'Darren', 'Darryl', 'David', 'Davis', 'Dawn', 'Deanna', 'Deborah', 'Debra', 'Dee', 'Delia', 'Demetra', 'Denise', 'Dennis', 'Denver', 'Derrick', 'Devin', 'Diana', 'Diane', 'Dionne', 'Dixie', 'Dolores', 'Don', 'Donald', 'Donna', 'Dora', 'Doris', 'Dorothea', 'Dorothy', 'Douglas', 'Drew', 'Dulce', 'Dulcie', 'Dustin', 'Dwight', 'Earl', 'Earline', 'Eddie', 'Edgar', 'Edward', 'Edwin', 'Eldon', 'Eleanor', 'Elijah', 'Elise', 'Elizabeth', 'Ellen', 'Elliott', 'Ellis', 'Elsa', 'Elsie', 'Elvira', 'Emerita', 'Emily', 'Emma', 'Emmanuel', 'Enedina', 'Eric', 'Erica', 'Erik', 'Erika', 'Erin', 'Ernest', 'Errol', 'Esther', 'Ethel', 'Etta', 'Eugene', 'Eula', 'Eunice', 'Eustolia', 'Evangeline', 'Evelyn', 'Everett', 'Fay', 'Faye', 'Felicia', 'Felix', 'Fernando', 'Fidel', 'Flavia', 'Fletcher', 'Florence', 'Flossie', 'Floyd', 'Frances', 'Francisco', 'Frank', 'Frankie', 'Franklin', 'Fred', 'Freddie', 'Gabrielle', 'Gary', 'Gayle', 'Gemma', 'Gene', 'George', 'Georgina', 'Gerald', 'Geraldine', 'Gertrude', 'Gilbert', 'Gino', 'Giuseppe', 'Gladys', 'Glen', 'Glenda', 'Glenn', 'Glenna', 'Gloria', 'Gordon', 'Grady', 'Gregory', 'Guadalupe', 'Guillermina', 'Guy', 'Gwendolyn', 'Harold', 'Harriett', 'Harrison', 'Harry', 'Hattie', 'Heath', 'Heather', 'Heidi', 'Helen', 'Henrietta', 'Henriette', 'Henry', 'Herman', 'Hester', 'Hilda', 'Howard', 'Hugh', 'Ignacia', 'Imelda', 'Imogene', 'Ira', 'Irene', 'Irvin', 'Isabel', 'Jack', 'Jacklyn', 'Jacob', 'Jaime', 'James', 'Jami', 'Jamie', 'Janet', 'Janice', 'Jared', 'Jason', 'Javier', 'Jay', 'Jean', 'Jeanette', 'Jeanna', 'Jeannette', 'Jeff', 'Jeffery', 'Jeffrey', 'Jennifer', 'Jenny', 'Jeremy', 'Jerome', 'Jerry', 'Jess', 'Jesse', 'Jessica', 'Jettie', 'Jill', 'Jim', 'Joann', 'Joanne', 'Jodi', 'Joe', 'Joel', 'Johanna', 'John', 'Johnathan', 'Johnathon', 'Johnny', 'Johnson', 'Jon', 'Jonathan', 'Jonathon', 'Jose', 'Joseph', 'Josephine', 'Joshua', 'Josie', 'Joy', 'Joyce', 'Juan', 'Juanita', 'Judith', 'Judy', 'Julia', 'Julie', 'June', 'Justin', 'Karen', 'Kari', 'Kate', 'Katherine', 'Kathleen', 'Kathryn', 'Kathy', 'Kecia', 'Keith', 'Kelley', 'Kelly', 'Kenda', 'Kenneth', 'Kent', 'Kerri', 'Kerrie', 'Kevin', 'Kim', 'Kimberley', 'Kimberly', 'Kirk', 'Kristen', 'Kristin', 'Krystal', 'Kyle', 'Lakeisha', 'Lance', 'Lane', 'Larry', 'Latasha', 'Latisha', 'Laura', 'Lauren', 'Lawrence', 'Leah', 'Leandro', 'Lee', 'Leila', 'Lena', 'Leo', 'Leonard', 'Leroy', 'Leslie', 'Lester', 'Lewis', 'Liana', 'Lillian', 'Lilly', 'Linda', 'Lindsay', 'Lionel', 'Lisa', 'Lisbeth', 'Lizzie', 'Lois', 'Lonnie', 'Lore', 'Loren', 'Loretta', 'Lori', 'Lorraine', 'Lou', 'Louis', 'Louise', 'Lourdes', 'Lucas', 'Lucille', 'Luella', 'Luis', 'Lula', 'Luther', 'Lynda', 'Lynn', 'Mabel', 'Machelle', 'Mack', 'Madonna', 'Maida', 'Malcolm', 'Manuel', 'Marci', 'Margaret', 'Margaretta', 'Margarita', 'Marge', 'Marguerite', 'Maria', 'Marian', 'Marianne', 'Marie', 'Marilyn', 'Marina', 'Mario', 'Marissa', 'Marjorie', 'Mark', 'Marlene', 'Marsha', 'Martha', 'Martin', 'Marvin', 'Mary', 'Maryann', 'Matthew', 'Maura', 'Maureen', 'Max', 'Maxine', 'May', 'Maynard', 'Melanie', 'Melba', 'Melissa', 'Melody', 'Melvin', 'Merlin', 'Michael', 'Michaele', 'Micheal', 'Michele', 'Michell', 'Michelle', 'Mickey', 'Miguel', 'Mike', 'Mildred', 'Milo', 'Milton', 'Minnie', 'Miriam', 'Mitchell', 'Mollie', 'Molly', 'Mona', 'Monet', 'Monica', 'Morgan', 'Myrna', 'Nadia', 'Nancy', 'Naomi', 'Natalia', 'Natasha', 'Nettie', 'Newton', 'Nicholas', 'Nichole', 'Nicolas', 'Nicole', 'Noe', 'Nola', 'Nora', 'Noreen', 'Norman', 'Numbers', 'Oliver', 'Orlando', 'Orville', 'Oscar', 'Otto', 'Ouida', 'Pablo', 'Pamela', 'Pat', 'Patria', 'Patrice', 'Patricia', 'Patrick', 'Patty', 'Paul', 'Paulette', 'Pauline', 'Pedro', 'Peggy', 'Pennie', 'Pete', 'Peter', 'Philip', 'Phillip', 'Phuong', 'Phyllis', 'Preston', 'Rachel', 'Ralph', 'Ramiro', 'Ramon', 'Randall', 'Randi', 'Raquel', 'Raul', 'Ray', 'Raymond', 'Rebbeca', 'Rebecca', 'Rebekah', 'Regina', 'Rene', 'Renee', 'Reta', 'Reynaldo', 'Rhonda', 'Rich', 'Richard', 'Rick', 'Ricky', 'Rigoberto', 'Rita', 'Robert', 'Roberta', 'Roberto', 'Robin', 'Robyn', 'Rodney', 'Roger', 'Ronald', 'Rosa', 'Rosalee', 'Roscoe', 'Rose', 'Rosemary', 'Rosetta', 'Rosie', 'Ross', 'Roy', 'Ruby', 'Rudolph', 'Rufus', 'Russell', 'Ruth', 'Ryan', 'Sabrina', 'Salvatore', 'Samantha', 'Samuel', 'Sandra', 'Sandy', 'Santa', 'Sara', 'Sarah', 'Scott', 'Sean', 'Serena', 'Seth', 'Shana', 'Shane', 'Shantel', 'Sharon', 'Shawn', 'Sheila', 'Sherman', 'Shirely', 'Shirley', 'Sidney', 'Simon', 'Sofia', 'Spencer', 'Stacy', 'Stanley', 'Stephan', 'Stephane', 'Stephanie', 'Stephen', 'Steve', 'Steven', 'Stuart', 'Suanne', 'Sue', 'Susan', 'Sybil', 'Tammy', 'Ted', 'Tera', 'Teresa', 'Teresita', 'Thelma', 'Theodore', 'Theresa', 'Thomas', 'Tim', 'Timmy', 'Timothy', 'Tina', 'Todd', 'Tom', 'Tommy', 'Toni', 'Tony', 'Tracey', 'Traci', 'Tracy', 'Travis', 'Trista', 'Troy', 'Tyrone', 'Valerie', 'Vanessa', 'Vanetta', 'Venita', 'Verdie', 'Verna', 'Vernon', 'Veronica', 'Vickie', 'Victor', 'Victoria', 'Vincent', 'Violet', 'Virginia', 'Vivian', 'Wallace', 'Warren', 'Wayne', 'Wendy', 'Wesley', 'Wilbert', 'Wilhelmina', 'Willene', 'William', 'Willie', 'Wm', 'Young', 'Yvonne']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "# === PHASE 1: Gather ALL unique names ===\n",
    "all_names = set()\n",
    "\n",
    "def extract_names_from_proof_state(ps_str: str, collector: set):\n",
    "    \"\"\"\n",
    "    Parse the proof_state string via ast.literal_eval,\n",
    "    then walk every (head, body) pair and collect all names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rules = ast.literal_eval(ps_str)\n",
    "    except Exception:\n",
    "        return\n",
    "    for rule in rules:\n",
    "        for head, body in rule.items():\n",
    "            # head is a tuple (e.g. ('Johanna','father','Henry'))\n",
    "            collector.add(head[0])\n",
    "            collector.add(head[2])\n",
    "            # body is a list of triplets\n",
    "            for trip in body:\n",
    "                collector.add(trip[0])\n",
    "                collector.add(trip[2])\n",
    "\n",
    "def extract_bracketed_names(text: str, collector: set):\n",
    "    \"\"\"\n",
    "    Regex that finds [Name] in story/text_target.\n",
    "    \"\"\"\n",
    "    found = re.findall(r\"\\[([A-Za-z]+)\\]\", text)\n",
    "    collector.update(found)\n",
    "\n",
    "\n",
    "# 1) Directory where all your CSVs live\n",
    "BASE_DIR = \"./data_emnlp_final/\"\n",
    "\n",
    "for root, _, files in os.walk(BASE_DIR):\n",
    "    for fname in files:\n",
    "        if not fname.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "        path = os.path.join(root, fname)\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # 1a) From proof_state column\n",
    "        if 'proof_state' in df.columns:\n",
    "            for ps in df['proof_state'].dropna().astype(str):\n",
    "                extract_names_from_proof_state(ps, all_names)\n",
    "        \n",
    "        # 1b) From story column bracketed names\n",
    "        if 'story' in df.columns:\n",
    "            for s in df['story'].dropna().astype(str):\n",
    "                extract_bracketed_names(s, all_names)\n",
    "        \n",
    "        # (optionally) also from text_target if you want\n",
    "        if 'text_target' in df.columns:\n",
    "            for t in df['text_target'].dropna().astype(str):\n",
    "                extract_bracketed_names(t, all_names)\n",
    "\n",
    "print(f\"Found {len(all_names)} distinct names:\", sorted(all_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9155b690-ea8c-4dca-94bc-f9cbb0b6eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import re\n",
    "import random\n",
    "import ast\n",
    "import pandas as pd\n",
    "BASE_DIR = \"./data_emnlp_final/\"\n",
    "\n",
    "random.seed(2025)\n",
    "\n",
    "MALE_PL = [\"Ram\",\"Shyam\",\"Vishak\",\"Sunil\",\"Rahul\",\"Amit\",\"Rakesh\",\"Anuj\",\"Varun\",\"Nikhil\",\n",
    "           \"Arun\",\"Suresh\",\"Rohit\",\"Manish\",\"Vikas\",\"Pankaj\",\"Neeraj\",\"Rajesh\",\"Sanjeev\",\"Ramesh\",\n",
    "           'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
    "FEMALE_PL = [\"Priya\",\"Anita\",\"Neha\",\"Sonia\",\"Deepa\",\"Priyanka\",\"Sneha\",\"Pooja\",\"Anjali\",\"Geeta\",\n",
    "             'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "             \"Meena\",\"Lakshmi\",\"Neetu\",\"Kavita\",\"Reena\",\"Komal\",\"Swati\",\"Manju\",\"Ritu\",\"Usha\"]\n",
    "\n",
    "def parse_genders(gstr):\n",
    "    return dict(item.split(\":\") for item in gstr.split(\",\"))\n",
    "\n",
    "def extract_unique_names(row):\n",
    "    names = []\n",
    "    # proof_state extraction\n",
    "    try:\n",
    "        rules = ast.literal_eval(row['proof_state'])\n",
    "        for rule in rules:\n",
    "            for head, body in rule.items():\n",
    "                for n in (head[0], head[2]):\n",
    "                    if n not in names: names.append(n)\n",
    "                for trip in body:\n",
    "                    for n in (trip[0], trip[2]):\n",
    "                        if n not in names: names.append(n)\n",
    "    except:\n",
    "        pass\n",
    "    # bracketed tokens\n",
    "    for tok in re.findall(r\"\\[([A-Za-z]+)\\]\", row['story'] or \"\"):\n",
    "        if tok not in names: names.append(tok)\n",
    "    return names\n",
    "\n",
    "def build_row_mapping(unique_names, gender_map, replace_prob=0.8):\n",
    "    # 1) Split keep vs replace\n",
    "    to_keep    = [n for n in unique_names if random.random() >= replace_prob]\n",
    "    to_replace = [n for n in unique_names if n not in to_keep]\n",
    "    \n",
    "    # 2) Partition by gender\n",
    "    male_names   = [n for n in to_replace if gender_map.get(n) == \"male\"]\n",
    "    female_names = [n for n in to_replace if gender_map.get(n) == \"female\"]\n",
    "    \n",
    "    # 3) Sample placeholders without replacement\n",
    "    if len(male_names) > len(MALE_PL) or len(female_names) > len(FEMALE_PL):\n",
    "        raise ValueError(\"Placeholder pool too small for this row!\")\n",
    "    male_map   = dict(zip(male_names,   random.sample(MALE_PL,   len(male_names))))\n",
    "    female_map = dict(zip(female_names, random.sample(FEMALE_PL, len(female_names))))\n",
    "    \n",
    "    # 4) Combine into final mapping (keep originals too)\n",
    "    mapping = {n: n for n in to_keep}\n",
    "    mapping.update(male_map)\n",
    "    mapping.update(female_map)\n",
    "    return mapping\n",
    "\n",
    "def anonymize_text(text, mapping):\n",
    "    for orig, new in mapping.items():\n",
    "        text = re.sub(rf\"\\[{re.escape(orig)}\\]\",    f\"[{new}]\",    text)\n",
    "        text = re.sub(rf\"\\[{re.escape(orig)}\\]'s\", f\"[{new}]'s\", text)\n",
    "    return text\n",
    "\n",
    "def process_df(df):\n",
    "    stories, targets = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        gender_map   = parse_genders(row['genders'])\n",
    "        unique_names = extract_unique_names(row)\n",
    "        row_map      = build_row_mapping(unique_names, gender_map)\n",
    "        stories.append(anonymize_text(row['story'],       row_map))\n",
    "        targets.append(anonymize_text(row['text_target'], row_map))\n",
    "    df = df.copy()\n",
    "    df['story_anonymized']       = stories\n",
    "    df['text_target_anonymized'] = targets\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef1322d5-7d4f-4542-a7de-8a092787f83f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./data_emnlp_final/data_db9b8f04/1.10_test.csv → ./revised_data_emnlp/1.10_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.5_test.csv → ./revised_data_emnlp/1.5_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.9_test.csv → ./revised_data_emnlp/1.9_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.7_test.csv → ./revised_data_emnlp/1.7_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.8_test.csv → ./revised_data_emnlp/1.8_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.3_test.csv → ./revised_data_emnlp/1.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.2,1.3,1.4_train.csv → ./revised_data_emnlp/1.2,1.3,1.4_train_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.2_test.csv → ./revised_data_emnlp/1.2_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.6_test.csv → ./revised_data_emnlp/1.6_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_db9b8f04/1.4_test.csv → ./revised_data_emnlp/1.4_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.10_test.csv → ./revised_data_emnlp/1.10_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.5_test.csv → ./revised_data_emnlp/1.5_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.9_test.csv → ./revised_data_emnlp/1.9_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.7_test.csv → ./revised_data_emnlp/1.7_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.8_test.csv → ./revised_data_emnlp/1.8_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.3_test.csv → ./revised_data_emnlp/1.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.2_test.csv → ./revised_data_emnlp/1.2_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.6_test.csv → ./revised_data_emnlp/1.6_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.4_test.csv → ./revised_data_emnlp/1.4_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_089907f8/1.2,1.3_train.csv → ./revised_data_emnlp/1.2,1.3_train_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_523348e6/3.3_test.csv → ./revised_data_emnlp/3.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_523348e6/3.2_test.csv → ./revised_data_emnlp/3.2_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_523348e6/2.3_test.csv → ./revised_data_emnlp/2.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_523348e6/4.3_test.csv → ./revised_data_emnlp/4.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_523348e6/3.2,3.3_train.csv → ./revised_data_emnlp/3.2,3.3_train_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_523348e6/1.3_test.csv → ./revised_data_emnlp/1.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_7c5b0e70/3.3_test.csv → ./revised_data_emnlp/3.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_7c5b0e70/2.3_test.csv → ./revised_data_emnlp/2.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_7c5b0e70/4.3_test.csv → ./revised_data_emnlp/4.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_7c5b0e70/1.3_test.csv → ./revised_data_emnlp/1.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_7c5b0e70/1.2_test.csv → ./revised_data_emnlp/1.2_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_7c5b0e70/1.2,1.3_train.csv → ./revised_data_emnlp/1.2,1.3_train_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_d83ecc3e/4.2,4.3_train.csv → ./revised_data_emnlp/4.2,4.3_train_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_d83ecc3e/3.3_test.csv → ./revised_data_emnlp/3.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_d83ecc3e/2.3_test.csv → ./revised_data_emnlp/2.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_d83ecc3e/4.3_test.csv → ./revised_data_emnlp/4.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_d83ecc3e/1.3_test.csv → ./revised_data_emnlp/1.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_d83ecc3e/4.2_test.csv → ./revised_data_emnlp/4.2_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/3.3_test.csv → ./revised_data_emnlp/3.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/2.3_test.csv → ./revised_data_emnlp/2.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/2.2,2.3_train.csv → ./revised_data_emnlp/2.2,2.3_train_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/4.3_test.csv → ./revised_data_emnlp/4.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/2.2_test.csv → ./revised_data_emnlp/2.2_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/1.3_test.csv → ./revised_data_emnlp/1.3_test_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/.ipynb_checkpoints/2.2,2.3_train-checkpoint.csv → ./revised_data_emnlp/2.2,2.3_train-checkpoint_anonymized.csv ... done\n",
      "Processing ./data_emnlp_final/data_06b8f2a1/.ipynb_checkpoints/2.3_test-checkpoint.csv → ./revised_data_emnlp/2.3_test-checkpoint_anonymized.csv ... done\n"
     ]
    }
   ],
   "source": [
    "for root, _, files in os.walk(BASE_DIR):\n",
    "    for fname in files:\n",
    "        if not fname.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "        \n",
    "        in_path  = os.path.join(root, fname)\n",
    "        out_path = os.path.join(\n",
    "            \"./revised_data_emnlp\",\n",
    "            fname.replace(\".csv\", \"_anonymized.csv\")\n",
    "        )\n",
    "        \n",
    "        print(f\"Processing {in_path} → {out_path}\", end=\" ... \")\n",
    "        df = pd.read_csv(in_path)\n",
    "        df_out = process_df(df)\n",
    "        df_out.to_csv(out_path, index=False)\n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6e0655d-0d0d-4cfb-a09c-9952346c79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./revised_data_emnlp/1.2,1.3,1.4_train_anonymized.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce09ac59-a724-4dbb-b570-13e637dfbc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[George] is frustrated teaching his son how to drive. His son is [Douglas]. [Douglas] loves spending time with his uncle [Wayne].'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = df.iloc[10]\n",
    "\n",
    "raw['story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c159e868-ac69-4f60-96ff-579da4af3a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[George] is frustrated teaching his son how to drive. His son is [Manish]. [Manish] loves spending time with his uncle [Suresh].'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['story_anonymized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac815b3-5bda-44bf-bc8b-6bfa2626a042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e4274-2fb6-4f21-8832-d32095b56645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
